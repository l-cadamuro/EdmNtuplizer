[CRAB]
jobtype = cmssw
;scheduler = glite          ; nessun problema di numero job ma max 1 dataset utilizzabile
scheduler = remoteGlidein   ; non si possono lanciare > 500 job alla volta --> submit 1-500 e 500-Njobs in comandi separati. Ma solo lui puo girare su >1 dataset
;use_server = 1
use_server = 0

[CMSSW]
;dbs_url = http://cmsdbsprod.cern.ch/cms_dbs_prod_global/servlet/DBSServlet
; datasetpath = /SingleElectron/Run2012D-PromptReco-v1/AOD
dbs_url = https://cmsweb.cern.ch/dbs/prod/global/DBSReader   ; url dove prendere i dataset (global/physics01/physics02/...)
use_dbs3=1      ; tipicamente e 3, comunque controllare su CMS DAS (DBS)
;run_selection=203773-205647
; pset = eleTreeProd_L1Study_2012D_PRV1.py
; pset = eleTreeProd_L1Study_with_opts.py
total_number_of_events = -1
events_per_job = 50000
; datasetpath=/DYJetsToLL_M-50_13TeV-pythia6/Fall13dr-tsg_PU40bx25_POSTLS162_V2-v1/GEN-SIM-RAW
datasetpath=/Neutrino_Pt-2to20_gun/Fall13dr-tsg_PU40bx25_POSTLS162_V2-v1/GEN-SIM-RAW               ; NOTA: sovrascrive il data path nel python di configurazione (test folder)

pset=../produceStage2.py            ; impostare il file di configurazione di CMSSW da lanciare
;total_number_of_lumis = -1         ; seleziona la luminosita max degli eventi (con i dati)
;lumis_per_job = 50                 ; luminosita per ogni job --> controllo la size di ogni job (perche parallellizzo il calcolo del dataset in piu job paralleli)       
output_file = tree_stage2.root      ; deve coincidere con lo stesso nome indicato nel python config file (oppure non lo specifico)
allow_NonProductionCMSSW = 1        ; ??

[USER]
; return_data=0
ui_working_dir=./ZeroBias_Stage2_Sept26_IsoEt_vTest5_bis_LucaTest_B1/  ; la cartella con i log, gli std output, i parametri (TGZ folder) etc... --> la crea lui, non deve esistere  --> cambiare nome o si blocca perche il folder eiste gia
copy_data=1           ; copia i dati nello storage element (per produrre i rootfile di output)
; publish_data=0      ; per pat-uple o ntuple per una twiki ufficiale/dataset, pubblica il nome del file nel CMS DAS
storage_element=T2_FR_GRIF_LLR    ; storage element
user_remote_dir = L1_trees/Stage2Trees/Neutrino_Pt-2to20_gun/Fall13dr-tsg_PU40bx25_POSTLS162_V2-v1/GEN-SIM-RAW/ZeroBias_Stage2_Sept26_IsoEt_vTest5_bis_LucaTest_B1/    ; directory di output per i rootfile --> spazio dbs

[GRID]
;ce_white_list = T2_CH_CERN,T2_FR_IPHC
;
;to run at GRIF with local priority
;dont_check_proxy= 1 
;user has to take care of the proxy.
;virtual_organization=vo.llr.in2p3.fr 
;wms_service=https://grid25.lal.in2p3.fr:7443/glite_wms_wmproxy_server
;se_white_list= polgrid4.in2p3.fr
